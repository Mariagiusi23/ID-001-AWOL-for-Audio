# ğŸŒ€ AWOL for Audio â€” Language-to-Sound Generation via Parametric Synthesis

**DLAI 2024/2025 Project â€” ID001**  
_Author: Mariagiusi Nicodemoâ€¢ Based on CLAP + RealNVP + FM Synthesis_

This project explores generating sound from text descriptions by adapting the AWOL (Analysis Without synthesis using Language) framework from 3D to the audio domain. The system learns to map natural language prompts to the parameters of a procedural FM synthesizer using MLP and RealNVP models.

---

## ğŸ¯ Objective

Translate the AWOL framework from 3D geometry to sound generation by:

- Using CLAP embeddings from textual prompts,
- Mapping embeddings to synthesis parameters via learnable models,
- Rendering semantically coherent and controllable audio,
- Exploring interpolation/extrapolation in latent space.

---

## ğŸ“ Repository Structure

All notebooks are in the `notebook/` folder. You can run them directly on Google Colab:

| Notebook | Description | Open in Colab |
|----------|-------------|----------------|
| `01_BaselineClapEmbeddingToFmSynthesis.ipynb` | Baseline pipeline CLAP â†’ MLP â†’ FM synth (no training). | [ğŸµ Open](https://colab.research.google.com/github/Mariagiusi23/ID-001-AWOL-for-Audio/blob/main/notebook/01_BaselineClapEmbeddingToFmSynthesis.ipynb) |
| `02_AWOL_SupervisedMapping.ipynb` | Supervised training of the MLP model on a manual dataset. | [ğŸµ Open](https://colab.research.google.com/github/Mariagiusi23/ID-001-AWOL-for-Audio/blob/main/notebook/02_AWOL_SupervisedMapping.ipynb) |
| `03_AWOL_RealnvpMapping.ipynb` | RealNVP implementation for semantic â†’ audio parameter mapping. | [ğŸµ Open](https://colab.research.google.com/github/Mariagiusi23/ID-001-AWOL-for-Audio/blob/main/notebook/03_AWOL_RealnvpMapping.ipynb) |
| `04_AWOL_LatentSpaceExploration.ipynb` | Latent space interpolation, baseline comparison, Gradio demo. | [ğŸµ Open](https://colab.research.google.com/github/Mariagiusi23/ID-001-AWOL-for-Audio/blob/main/notebook/04_AWOL_LatentSpaceExploration.ipynb) |


---

